{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def capture_histogram(source):\n",
    "    cap=cv2.VideoCapture(source)\n",
    "    while True:\n",
    "        _,frame=cap.read()\n",
    "        frame=cv2.flip(frame,1)\n",
    "        frame=cv2.resize(frame,(1000,600))\n",
    "        \n",
    "        font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,'Place region of hand in sied the box and press a',(5,50),font,0.7,(255,255,255),2,cv2.LINE_AA)\n",
    "        #above line is for text display above the box\n",
    "        cv2.rectangle(frame,(500,100),(580,180),(105,105,105),2)\n",
    "        box = frame[105:175,505:575]\n",
    "        \n",
    "        cv2.imshow(\"capture Histogram\",frame)\n",
    "        key=cv2.waitKey(10)\n",
    "        if key == ord('a'):\n",
    "            object_color = frame\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        if key == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            cap.release()\n",
    "            break\n",
    "    object_color_hsv=cv2.cvtColor(object_color,cv2.COLOR_BGR2HSV)\n",
    "    object_hist=cv2.calcHist([object_color_hsv],[0,1],None,[12,15],[0,180,0,256])\n",
    "    cv2.normalize(object_hist,object_hist,0,255,cv2.NORM_MINMAX)\n",
    "    return object_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_object(frame,object_hist):\n",
    "    hsv_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    #apply back propagation to image using object_hist as\n",
    "    object_segment=cv2.calcBackProject([hsv_frame],[0,1],object_hist,[0,180,0,256],1)\n",
    "    _,segment_thresh=cv2.threshold(object_segment,20,255,cv2.THRESH_BINARY)\n",
    "    #APPLYING SOME IMAGE OPERATIONS TO ENHANCE IMAGE\n",
    "    kernel=None\n",
    "    disc=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(15,15))\n",
    "    filtered=cv2.filter2D(segment_thresh,-1,disc)\n",
    "    \n",
    "    eroded=cv2.erode(filtered,kernel,iterations=2)\n",
    "    dilated=cv2.dilate(eroded,kernel,iterations=2)\n",
    "    closing=cv2.morphologyEx(dilated,cv2.MORPH_CLOSE,kernel)\n",
    "    \n",
    "    #masking\n",
    "    masked=cv2.bitwise_and(frame,frame,mask=closing)\n",
    "    \n",
    "    return closing,masked,segment_thresh\n",
    "\n",
    "def detect_hand(frame,hist):\n",
    "    return_value={}\n",
    "    detect_hand,masked,raw=locate_object(frame,hist)\n",
    "    return_value[\"binary\"]=detect_hand\n",
    "    return_value[\"masked\"]=masked\n",
    "    return_value[\"raw\"]=raw\n",
    "    \n",
    "    image,contours=cv2.findContours(detect_hand,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    palm_area=0\n",
    "    flag=None\n",
    "    cnt=None\n",
    "    \n",
    "    for (i,c) in enumerate(contours):\n",
    "        area=cv2.contourArea(c)\n",
    "        if area>palm_area:\n",
    "            palm_area=area\n",
    "            flag=i\n",
    "    if flag is not None and palm_area > 10000:\n",
    "        cnt=contours[flag]\n",
    "        return_value[\"contours\"]=cnt# largest contour which we found\n",
    "        cpy=frame.copy()\n",
    "        cv2.drawContours(cpy,[cnt],0,(0,255,0),2)\n",
    "        return_value[\"boundaries\"]=cpy\n",
    "        return True,return_value\n",
    "    else:\n",
    "        return False, return_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'object_color' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-634603a3371c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcapture_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-aa110b418cd1>\u001b[0m in \u001b[0;36mcapture_histogram\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mobject_color_hsv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_color\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mobject_hist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcHist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobject_color_hsv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_hist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobject_hist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNORM_MINMAX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'object_color' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#from HandRecognition import *\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "hist=capture_histogram(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    hand_detected,hand=detect_hand(frame,hist)\n",
    "    if hand_detected:\n",
    "        hand_image=hand[\"boundaries\"]\n",
    "        cv2.imshow(\"Hand Detector\",hand_image)\n",
    "    else:\n",
    "        cv2.imshow(\"Hand Detector1\",frame)\n",
    "    #cv2.imshow(\"Raw\",hand[\"raw\"])\n",
    "    #cv2.imshow(\"Enhanced Binary\",hand[\"binary\"])\n",
    "    #cv2.imshow(\"Masked\",hand[\"masked\"])\n",
    "    \n",
    "    k=cv2.waitKey(10)\n",
    "    if k==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\shapedescr.cpp:274: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'cv::contourArea'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ffb0aa3c8a48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mhand_detected\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetect_hand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhand_detected\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mhand_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhand\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"boundaries\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-40b94d0f3244>\u001b[0m in \u001b[0;36mdetect_hand\u001b[1;34m(frame, hist)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0marea\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0marea\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mpalm_area\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mpalm_area\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marea\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\shapedescr.cpp:274: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'cv::contourArea'\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
